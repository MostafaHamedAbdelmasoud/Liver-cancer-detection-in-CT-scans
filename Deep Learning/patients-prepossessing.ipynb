{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pydicom, neccessary libraries and loading data\n",
    "* Dicom (Digital Imaging in Medicine) is the bread and butter of medical image datasets, storage and transfer.\n",
    "* Reading dicom patients files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom \n",
    "import os \n",
    "import pandas as pd  \n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# patients paths\n",
    "patients = []\n",
    "for i in range(15):\n",
    "    s1 = \"3Dircadb1/3Dircadb1.\"\n",
    "    s2 = \"/PATIENT_DICOM\"\n",
    "    patients.append(s1+str(i+1)+s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dicom patients\n",
    "patients_slices =[]\n",
    "for patient in patients:\n",
    "#     labels_df.get_value(patient, 'cancer')\n",
    "    path = patient\n",
    "    # a couple great 1-liners from: https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial\n",
    "    slices = [pydicom.read_file(path+\"/\" + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    patients_slices.append(slices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hounsfield Units \n",
    "\n",
    "* The unit of measurement in CT scans is the Hounsfield Unit (HU), which is a measure of radiodensity. CT scanners are carefully calibrated to accurately measure this. From Wikipedia:\n",
    "\n",
    "* By default however, the returned values are not in this unit. Let's fix this.\n",
    "\n",
    "* Some scanners have cylindrical scanning bounds, but the output image is square. The pixels that fall outside of these bounds get the fixed value -2000. The first step is setting these values to 0, which currently corresponds to air. Next, let's go back to HU units, by multiplying with the rescale slope and adding the intercept (which are conveniently stored in the metadata of the scans!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Hounsfield units (HU)\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "patients_pixels = []\n",
    "for patients in patients_slices:\n",
    "    first_patient_pixels = get_pixels_hu(patients)\n",
    "    patients_pixels.append(first_patient_pixels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "* A commonly used set of thresholds to normalize is -200 and 500.\n",
    "* Our values currently range from -1024 to around 2000. Anything above 500 is not interesting to us these are simply bones with different radiodensity, and below -200 is just fats, lungs and air radiodensties. \n",
    "*  Here's some code you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize patients to focus on liver\n",
    "MIN_BOUND = - 200\n",
    "MAX_BOUND = 500\n",
    "\n",
    "normalized = []\n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "for pat in patients_pixels:\n",
    "    normalized.append(normalize(pat)) \n",
    "\n",
    "del patients_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "* A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)!\n",
    "\n",
    "* A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance.\n",
    "\n",
    "* Whilst this may seem like a very simple step, it has quite some edge cases due to rounding. Also, it takes quite a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resamble voxel to 1mm, 1mm, 1mm\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness, scan[0].PixelSpacing[0], scan[0].PixelSpacing[1]], dtype=np.float32)\n",
    "    \n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    image = image.astype(np.float32)\n",
    "    return image, new_spacing\n",
    "\n",
    "patients_resampled = []\n",
    "for i in range(15):\n",
    "    pix_resampled, spacing = resample( normalized[i], patients_slices[i], [1,1,1])\n",
    "    patients_resampled.append(pix_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving preproccessed patients offline\n",
    "\n",
    "* preproccessing is a time and memory consuming proccess so we prefare to save our clean and ready data offline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('offline-patients.npy',patients_resampled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
