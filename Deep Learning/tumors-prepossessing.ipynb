{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pydicom, neccessary libraries and loading data\n",
    "* Dicom (Digital Imaging in Medicine) is the bread and butter of medical image datasets, storage and transfer.\n",
    "* Reading dicom patients tumor masks files \n",
    "\n",
    "## Hounsfield Units \n",
    "\n",
    "* The unit of measurement in CT scans is the Hounsfield Unit (HU), which is a measure of radiodensity. CT scanners are carefully calibrated to accurately measure this. From Wikipedia:\n",
    "\n",
    "* By default however, the returned values are not in this unit. Let's fix this.\n",
    "\n",
    "* Some scanners have cylindrical scanning bounds, but the output image is square. The pixels that fall outside of these bounds get the fixed value -2000. The first step is setting these values to 0, which currently corresponds to air. Next, let's go back to HU units, by multiplying with the rescale slope and adding the intercept (which are conveniently stored in the metadata of the scans!).\n",
    "\n",
    "## Normalization\n",
    "* A commonly used set of thresholds to normalize is -200 and 500.\n",
    "* Our values currently range from -1024 to around 2000. Anything above 500 is not interesting to us these are simply bones with different radiodensity, and below -200 is just fats, lungs and air radiodensties. \n",
    "*  Here's some code you can use\n",
    "\n",
    "## Resampling\n",
    "\n",
    "* A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)!\n",
    "\n",
    "* A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance.\n",
    "\n",
    "* Whilst this may seem like a very simple step, it has quite some edge cases due to rounding. Also, it takes quite a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbAQ_S_n6-yV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os # for doing directory operations \n",
    "import pandas as pd # for some simple data analysis (right now, just to load in the labels data and quickly reference it)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDiiGUKxID90"
   },
   "outputs": [],
   "source": [
    "#returns the hounse fied unit of slices \n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "\n",
    "def normalize2(image):\n",
    "    MAX_BOUND = np.max(image)\n",
    "    MIN_BOUND = np.min(image)\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "\n",
    "#resample the image to 1mm in all diminsions \n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness, scan[0].PixelSpacing[0], scan[0].PixelSpacing[1]], dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_segm(tumur_count = [7,1,1,1,1,3,1,1,1,1,1,1,2,1,1]):\n",
    "    tumor_segm = []\n",
    "    pathes = []\n",
    "    for i in range(15):\n",
    "        s1 = \"3Dircadb1/3Dircadb1.\"\n",
    "        s2 = \"/MASKS_DICOM/livertumor0\"\n",
    "        if tumur_count[i] == 1:\n",
    "            pathes.append([s1+str(i+1)+s2+'1'])\n",
    "        else:\n",
    "            l = []\n",
    "            for k in range(tumur_count[i]):\n",
    "                l.append(s1+str(i+1)+s2+str(k+1))\n",
    "            pathes.append(l)\n",
    "\n",
    "    \n",
    "    \n",
    "    tumor_slices = []\n",
    "    tumor_norm = []\n",
    "    for path in pathes:\n",
    "        if len(path) == 1:\n",
    "            slices = [pydicom.read_file(path[0]+\"/\" + s) for s in os.listdir(path[0])]\n",
    "            slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "            tumor_slices.append(slices)\n",
    "            hf_3d = get_pixels_hu(slices)\n",
    "            norm = normalize2(hf_3d)\n",
    "            tumor_norm.append(norm)\n",
    "            \n",
    "        else:\n",
    "            slices1 = [pydicom.read_file(path[0]+\"/\" + s) for s in os.listdir(path[0])]\n",
    "            slices1.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "            tumor_slices.append(slices1)\n",
    "            dumy = get_pixels_hu(slices1)\n",
    "            add = np.zeros(shape = dumy.shape)\n",
    "            for k in range(len(path)):\n",
    "                slices = [pydicom.read_file(path[k]+\"/\" + s) for s in os.listdir(path[k])]\n",
    "                slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "                hf_3d = get_pixels_hu(slices)\n",
    "                norm = normalize2(hf_3d)\n",
    "                add = add + norm\n",
    "            tumor_norm.append(add)\n",
    "\n",
    "    return tumor_norm,tumor_slices\n",
    "\n",
    "normalized_tumor,tumor_slices = tumor_segm()\n",
    "\n",
    "\n",
    "tumors_resampled = []\n",
    "for i in range(15):\n",
    "    pix_resampled = resample( normalized_tumor[i], tumor_slices[i], [1,1,1])\n",
    "    tumors_resampled.append(pix_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving preproccessed patients tumor masks offline\n",
    "\n",
    "* preproccessing is a time and memory consuming proccess so we prefare to save our clean and ready data offline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('offline-tumors.npy',tumors_resampled)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "preproc_predictig.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
